[toc]


# 每天复习路线

1. 数据结构和算法：

https://www.yuque.com/yfgo/yv2fmp

2. 下面的基础知识
3. 校招直通车
4. 面经知识

# 公司路径记录



# 个人介绍

我叫胡云飞，目前是大三下学期，自从大一入学开始，通过面试进入三月软件实验室，在实验室中通过课余时间和假期自学计算机相关知识。

大二开始参与实验室内项目开发，到目前为止，也算是有了近一年的项目开发经历，经历了vue项目一个，python项目一个，Go项目两个，都是和其它单位合作的项目。比如大二经历的这个前端项目是当时我的本校河南科技学院需要把一批7000人左右的报道搬到线上，把这个任务交给了我的实验室，我和一些人就参与开发了这个线上迎新报道系统，我在其中负责部分模块的前端开发。

从入这个实验室开始到现在，期间也担任了多个职务，比如组长，班长，各种事情的负责人，身上的职务也在不断的变化，但一直没断过，今年实验室内开设了一个新的部门，里面有两组，我是其中一组的负责人，在管理和解决问题上我也有很多自己的思考和想法。 

学习之余我也喜欢运动，阅读和写作，打得一手在业余中还不错的乒乓球，除了专业上的书籍一直在看，其它的书也都看过一点，平时定期进行写作，审查和反省自己。

我在网站上了解到贵公司，也想和贵公司进一步的交流，看看自己是否适合贵公司的职位。

## 反问

1. 您在公司的一天是如何度过的？
2. 对您来说，您在公司中遇到最困难的事情是什么？
3. 如果面试总分为10分，您给我打几分？您打分的依据是什么？
4. 在整个面试中，我有哪些问题？
5. 如果我势必要进入到这个岗位中，我有哪些差距？

# Go

## 各个数据类型的内部实现

### go数据类型分类

使用var声明的变量的值会自动初始化为该类型的零值。

类型分为三种：

基本类型：int、float、bool、string   （值类型，直接指向内存中的值）

结构化的(复合的)：struct（值）、array（值）、slice、map、channel

只描述类型的行为的：interace

结构化类型并没有真正的值，它使用nil作为默认值。

Go是一种静态语言类型的语言，即每个值都必须在经过编译后属于某个类型。

值类型存储在栈中，引用类型存储在堆中。

值类型可以用new()来创建，返回类型指针

![image-20220217164225881](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220217164225881.png)

### Map的扩容机制



## GMP

G(Goroutine)：协程，用户级的轻量级线程。

M：对内核线程的封装

P：为G和M的调度对象，主要用途是用来执行goroutine，维护了一个goroutine队列，即runqueue

### 由来

#### 单进程时代

这个时代不需要调度器，早起的操作系统每个程序就是一个进程，直到一个程序运行完，才能进入下一个进程，一切的程序只能串行发生。

<img src="https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220217145618751.png" alt="image-20220217145618751" style="zoom:50%;" />

很容易出现的问题就是计算机只能一个一个的处理，而且如果某一进程在进行读写操作，进程阻塞会带来CPU时间的浪费。

#### 多进程/线程时代

后来操作系统具有最早的并发能力：多进程并发，当一个进程阻塞的时候，切换到另外等待执行的进程，这样就能尽量把CPU利用起来。

进程虚拟内存会占用4GB[32位操作系统]，而线程也要大约4MB。 大量的进程/线程出现新的问题：高内存占用，以及频繁调度带来的cpu损耗。

线程分为“内核态”线程和“用户态”线程，一个“用户态”线程必须要绑定一个“内核态”线程。

但是CPU对“用户态”线程是无感知的。  这样，就把用户态的“线程”叫为了协程。

这个时候，就发展为了多个协程绑定到一个线程上的模式。

##### N：1

N个协程绑定1个线程。   优点是协程的切换非常快速，缺点是一旦某协程阻塞，造成线程阻塞，本进程的其它协程都会法执行。

<img src="https://pic4.zhimg.com/80/v2-8ff808be2c4b14bd895e9bbeee309adb_720w.jpg" alt="img" style="zoom:50%;" />

##### 1:1

1个协程1个线程。

协程的调度由CPU完成。

##### M：N

克服了以上两种模型的缺点，实现起来也是最复杂的。

<img src="https://pic1.zhimg.com/80/v2-726f001a6a3633ca18388aef59f4396c_720w.jpg" alt="img" style="zoom:50%;" />

### 被废弃的goroutine调度器：GM

G表示Goroutine，M表示线程

M 想要执行、放回 G 都必须访问全局 G 队列，并且 M（线程） 有多个，即多线程访问同一资源需要加锁进行保证互斥 / 同步，所以全局 G 队列是有互斥锁进行保护的。

<img src="https://pic2.zhimg.com/80/v2-59e7385ef6405ccecab9f66187fa46f9_720w.jpg" alt="img" style="zoom:67%;" />

缺点：

1. 创建、销毁、调度 G 都需要每个 M 获取锁。
2. M之间的频繁切换增加系统开销

### GMP是什么？

在GM的基础上引进了P（处理器）。

通过调度器来把可运行的goroutine分配到工作线程上。

1. **全局队列**（Global Queue）：存放等待运行的 G。
2. **P 的本地队列**：同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。
3. **P 列表**：所有的 P 都在程序启动时创建，并保存在数组中，最多有 `GOMAXPROCS`(可配置) 个。
4. **M**：线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列**拿**一批 G 放到 P 的本地队列，或从其他 P 的本地队列**偷**一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。



![img](https://pic1.zhimg.com/80/v2-a851cc7ac7d3c4c8f0d33f5634473330_720w.jpg)

### GMP设计策略

**复用线程**：避免频繁的创建、销毁线程，而是对线程的复用。
1）work stealing 机制
 当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。
2）hand off 机制
 当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。

**抢占**：

goroutine最多占用CPU10ms，防止其它goroutine被饿死。

## GC

`STW` 可以是 `Stop the World` 的缩写，也可以是 `Start the World` 的缩写。通常意义上指指代从 `Stop the World` 这一动作发生时到 `Start the World` 这一动作发生时这一段时间间隔，即万物静止。

在这个过程中整个用户代码被停止或者放缓执行， `STW` 越长，对用户代码造成的影响（例如延迟）就越大。

### 三色标记法

将对象分为黑、灰、白三种颜色

白色：该对象还没有被标记过（对象垃圾）

灰色：该对象被标记过，但对象下的属性没有完全被标记完（GC需要从此对象中寻找垃圾）

黑色：该对象已经被标记过了，且该对象下的属性也全部都被标记过了（程序所需要的对象）

在垃圾收集器开始工作时，会先把所有对象放到白色区域，然后从GC Roots开始进行遍历访问：

1. GC Roots 根对象会被标记成灰色；
2. 然后从灰色集合中获取对象，将其标记为黑色，将该对象引用到的对象标记为灰色；
3. 重复步骤2，直到没有灰色集合可以标记为止；
4. 结束后，剩下的没有被标记的白色对象即为 GC Roots 不可达，可以进行回收。



![image-20220217152912879](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220217152912879.png)

流程大概如下：

![img](https://pic3.zhimg.com/80/v2-06a35dcb4b28e3afae17246253b9157a_720w.jpg)

#### 存在的问题

##### 多标-浮动垃圾问题

假设 E 已经被标记过了（变成灰色了），此时 D 和 E 断开了引用，按理来说对象 E/F/G 应该被回收的，但是因为 E 已经变为灰色了，其仍会被当作存活对象继续遍历下去。最终的结果是：这部分对象仍会被标记为存活，即本轮 GC 不会回收这部分内存。

这部分本应该回收 但是没有回收到的内存，被称之为“浮动垃圾”。过程如下图所示：

![image-20220217154753129](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220217154753129.png)

##### 漏标-悬挂指针问题

除了上面多标的问题，还有就是漏标问题。当 GC 线程已经遍历到 E 变成灰色，D变成黑色时，灰色 E 断开引用白色 G ，黑色 D 引用了白色 G。此时切回 GC 线程继续跑，因为 E 已经没有对 G 的引用了，所以不会将 G 放到灰色集合。尽管因为 D 重新引用了 G，但因为 D 已经是黑色了，不会再重新做遍历处理。

最终导致的结果是：G 会一直停留在白色集合中，最后被当作垃圾进行清除。这直接影响到了应用程序的正确性，是不可接受的，这也是 Go 需要在 GC 时解决的问题。

![image-20220217154815796](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220217154815796.png)

#### 解决方法：内存屏障

根据类型的不同将内存屏障分为读屏障、写屏障。  在Go中使用的是写屏障。

因为堆中的写操作远远小于堆中的读操作，写屏障代价更小。

##### 写屏障

如果D断开对E的引用，改成引用B对象，那么这时候触发写屏障将B对象标记成灰色。

![img](https://pic3.zhimg.com/80/v2-86fccb3f185bdcf9394aa809ead2e816_720w.jpg)



##### 删除写屏障

如果一个灰色对象指向一个白色对象的引用被删除，那么在删除之前写屏障检测到内存变化，就会把这个白色对象标灰。

##### 插入写屏障

如果两个对象之间新建立引用，那么引用指向的对象就会被标记为灰色

##### 混合写屏障

GC开始时栈扫黑，每个栈单独扫描，无需STW。堆上执行插入写和删除写屏障。

可以不适用STW。



# mysql

## 基础

- 第一范式：属性（字段）不可分割。不能再分成更小的单位了。

这个也根据需求而定，比如学生信息可以分为姓名、年龄、性别等信息，姓名不可再分。

但是如果这个表放在国外，姓和名要分开，都有特别的意义，所以姓名字段需要拆分为姓字段和名字段。

- 第二范式：要有主键。

而且其他字段都要依赖于主键，有主键就有唯一性。

比如学生信息表，姓名不能做主键，因为它不唯一，需要学号这样的唯一编码。

其它信息必须相关主键的意思是比如学号是主键，这么这一条信息只能存储这个学生的相关信息，不能是其它人的相关信息。

- 第三范式：消除传递依赖，也可以看做是消除冗余。

消除冗余应该比较好理解一些，就是各种信息只在一个地方存储，不出现在多张表中。

比如说大学分了很多系（中文系、英语系、计算机系……），这个系别管理表信息有以下字段组成：

系编号，系主任，系简介，系架构。

那么再回到学生信息表，张三同学的年龄、性别、学号都有了，我能不能把他的系编号，系主任、系简介也一起存着？

如果你问三范式，当然不行，因为三范式不同意。

因为系编号，系主任、系简介已经存在系别管理表中，你再存入学生信息表，就是冗余了。

三范式中说的传递依赖，就出现了。

那怎么才能在学生信息表中找到它的系主任？

按照三范式处理这个问题的时候，学生表只能增加一个系编号字段，这样既能根据系编号找到系别信息，又避免了冗余存储的问题。

**所谓的范式，是用来学习参考的，设计的时候根据情况，未必一定要遵守，切记。**

## 引擎

MySQL 支持多种存储引擎,比如 InnoDB,MyISAM,Memory,Archive 等等.在大多数的情况下,直接选择使用 InnoDB 引擎都是最合适的,InnoDB 也是 MySQL 的默认存储引擎。

MyISAM 和 InnoDB 的区别有哪些：

- InnoDB 支持事务，MyISAM 不支持
- InnoDB 支持外键，而 MyISAM 不支持
- InnoDB 是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高；MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的。
- Innodb 不支持全文索引，而 MyISAM 支持全文索引，查询效率上 MyISAM 要高；
- InnoDB 不保存表的具体行数，MyISAM 用一个变量保存了整个表的行数。
- MyISAM 采用表级锁(table-level locking)；InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。

### 约束

约束一共如下：

* NOT NULL: 用于控制字段的内容一定不能为空（NULL）。
* UNIQUE: 控制字段内容不能重复，一个表允许有多个 Unique 约束。
* PRIMARY KEY: 也是用于控制字段内容不能重复，但它在一个表只允许出现一个。
* FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。
* CHECK: 用于控制字段的值范围。

## 数据库事务

事务是一个不可分割的数据库操作序列，要么都执行，要么都不执行。

有以下四个特征：

- 原子性。事务中包含的各操作要么都做，要么都不做
- 一致性。事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是不一致的状态。
- 隔离性。一个事务的执行不能其它事务干扰。即一个事务内部的//操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。
- 持续性。也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。

### 事物实现原理、日志

MySql日志 主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志。

其中二进制日志`binlog`（归档日志）和事务日志`redo log`（重做日志）和`undo log`（回滚日志）比较重要。

#### redo log

适用于崩溃恢复。

是InnoDB存储引擎所独有的，让Mysql拥有了崩溃恢复能力。

如果MYSQL实例挂了或者宕机了，重启时InnoDB存储引擎会使用redolog恢复数据，保证数据持久性和完整性。

MySQL中数据是以页为单位，你查询一条记录，**会从硬盘把一页数据加载出来(数据页)**，会放入Buffer Pool中。

后续的查询都是先从Buffer Pool中找，没有命中再去硬盘加载，减少硬盘IO开销，提升性能
更新表的时候，发现Buffer Pool中存在要更新的数据，就直接从Buffer Pool里更新，然后会把"某个数据页上做了什么修改"记录到重做日志缓存(redo log buffer)里，接着刷盘到 redo log文件里。

每条 redo 记录由**“表空间号+数据页号+偏移量+修改数据长度+具体修改的数据”**组成.

![image-20220219131217407](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220219131217407.png)

我们都知道，事务的四大特性里面有一个是 **持久性** ，具体来说就是**只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态** 。

mysql保持持久性最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题，主要体现在两个方面：

1. 因为 `Innodb` 是以 `页` 为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！
2. 一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差！

所以"某个数据页上做了什么修改"记录到重做日志缓存(redo log buffer)里。

#### bin log

主从复制和数据恢复。

redo log是物理日志，记录内容类似于`在某个数据页上做了什么修改`，属于InnoDB存储引擎。

bin log是逻辑日志，记录内容是语句的原始逻辑，类似于`给ID=2这一行的c字段加1`，属于Mysql server层。

bin log会记录所有涉及更新数据的逻辑操作，并且是按顺序写入。

##### 三种记录格式

通过binlog_format参数指定：`statement`、`row`、`mixed`。

**statement：**记录SQL语句的原文，但是同步数据的时候可能会有一个问题，比如update_time=now()这一句，它会获取当前系统的时间，直接执行会导致和原来的数据不一致。

**row：**记录的不仅是简单的sql语句，还包含操作的具体数据。 update_time=now()变成了具体的时间update_time=1627112756247。这样就能保证同步数据的一致性，但是这种格式需要更大的容量来记录，比较占用时间，恢复和同步时也会更消耗IO资源。

**mixed：**混合模式。 这种情况下Mysql会根据执行的每一条具体的SQL语句来区分对待记录的日志形式。 也就是在statement和row中选择一种。

#### undo log

数据库事务四大特性中有一个是 **原子性** ，具体来说就是 **原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况**。

实际上， **原子性** 底层就是通过 `undo log` 实现的。`undo log`主要记录了数据的逻辑变化，比如一条 `INSERT` 语句，对应一条`DELETE` 的 `undo log` ，对于每个 `UPDATE` 语句，对应一条相反的 `UPDATE` 的 `undo log` ，这样在发生错误时，就能回滚到事务之前的数据状态。

undo log是需要基于当前数据，恢复到之前的某个时刻的。

### 并发中可能遇到的问题：脏读、幻读、不可重复读、丢失修改

脏读：事务B读取了事务A更新的数据，然后A回滚操作，事务B读到的数据是脏数据。

丢失修改：事务A和B同时读取了数据，分别对数据进行修改然后提交，导致前一个提交的事务修改丢失。

不可重复读：事务B两次读取a变量的值，期间事务A修改了a变量的值，导致事务B第二次读取a变量的值和第一次不一样。

幻读：事务A执行查询查到了3条数据，并对此进行修改，此时事务B插入了三条数据，事务A修改结束后再进行查询发现还有数据没有被修改，就好像发生了幻觉一样。

![image-20220218231707274](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220218231707274.png)

### 面对并发问题的解决方案：四种隔离级别

主要排除其它事务对本事务的影响。

- 读取未提交

所有事物都可以看到其他未提交事务的执行结果。很少用于实际应用。

读取未提交的数据，也被称为脏读。

- 读取提交内容

大多数数据库的默认隔离级别（但不是MySQL默认的），满足了隔离的简单定义：一个事物只能看见已经提交事务所做的改变。

这种隔离会导致`不可重复读`。

- 可重复读

这是MYSQL的默认事务隔离级别，确保同一事务的多个实例在并发读取数据的时候，会看到同样的数据行，在同一个事务中发出同一个select语句很多次，产生的结果总是相同的。

这会导致另一个问题：幻读。 但是MYSQL通过MVCC机制解决了幻读的问题。

- 可串行化

强制事务排序，使不能互相冲突，解决幻读问题。在这个级别可能会导致大量超时现象和锁竞争。

事务隔离机制的实现基于锁机制和并发调度，其中并发调度使用的是MVVC。

## 索引结构

索引是在存储引擎层面实现的，而不是server层面。

不是所有存储引擎都支持所有的索引类型，即使多个存储引擎支持某一索引类型，它们的实现和行为也可能有差别。

### 数据库的功能

那么数据库要完成这些功能的时候，它需要去选取对应的数据结构。

![image-20220219124448465](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220219124448465.png)

如果我们通过链表或数组来完成这个功能的话，主要的问题在于它增删查改的平均时间复杂度为O(n)，如果数据库有千万条数据的话，这个性能不是很高。

接下来，如果我们通过二叉搜索树来完成这个功能的话，所有比当前节点大的节点都在右子树，所有比当前节点小的节点都在左子树。 二叉搜索树可以保证有序，它的平均时间复杂度可以降到O(logn)。

![image-20220219124849939](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220219124849939.png)

不过最终也没有采用二叉搜索树这种数据结构，因为它可以在O(logn)的时间复杂度下`精确查找`到某个元素，但是如果给一个元素范围，长度为n，它就需要遍历n次这个树，找到这n个元素。时间复杂度为O(nlogn)，它的`范围查询`时间复杂度比较高。

但是也可以在二叉搜索树的基础上进行优化，解决这个问题。

![image-20220219125445113](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220219125445113.png)

最终呈现的效果如下，这样的话我们只需要找到一个范围的开始节点，就可以通过这个双向链表来进行范围查询了。

![image-20220219125620077](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220219125620077.png)

那为什么还要有B树、B+树？因为二叉搜索树有一个问题，就是它是二叉树，所以随着树高不断的扩展，会影响它的查询性能。

那么把二叉树变成多叉树，就是B+树。 

![image-20220219125733208](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220219125733208.png)

**B树和B+树的区别：**

- B树在叶子节点、根节点都保存数据，不利于范围查询。
- B+树根节点不存储数据，叶子使用双向链表连接，适合范围查询。
- 在插入数据、精确查询时，两者性能相近。

# redis

## 基础

链接：http://note.youdao.com/noteshare?id=d773afb5bef1893b761819e50a4ed906&sub=00B34157644E4E93A4F3613EBA86E7F5

## 常用类型及内部实现

常用五种数据类型：

1. 字符串String（set、get、mset、mget、setex 过期时间，setnx不存在则设置过期时间）。

字符串底层是简单动态字符串sds，是可以修改的字符串。 最大长度为512M。

当字符串长度小于1M时，扩容是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间。

SDS本质上是char *。

惰性空间释放用于优化SDS的字符串缩短操作。

**应用场景：**

- 缓存功能：字符串是各个语言的基本类型，可以比较方便的配合其它语言，或者数据库来利用Redis进行缓存。
- 共享用户Session：可以通过Redis将用户的Session集中管理。

2. 字典Hash（hset，hget，hmset，hmget，hgetall，hlen）

类似Map的结构，可以存放一些属性。

3. 列表List（lpush，rpush，lrange，lpop，rpop，消息队列 lpush rpop，栈 lpush lpop）

- 可以通过list存储列表型的数据结构，比如粉丝列表，文章评论列表之类。

- 也可以通过list来实现分页查询。

- 简单的消息队列

4. 集合Set（sadd添加set值，smembers查看所有值，sismember判断是否存在，srandmember随机获取元素，spop随机删除）

- 会自动去重
- 可以通过交并差集做一些事情。 比如两个人的好友做交集，就是两人的共同好友。



5. 有序集合SortedSet

排序的Set，去重并排序，写入的时候可以给一个分数，自动根据分数排序。

- 排行榜
- 带权重的队列，比如普通消息的score为1，重要消息为2。 然后可以先完成重要消息。

Redis中高级用户，还要知道下面几种数据结构：

6. HyperLogLog 基数统计算法。  统计在一个集合中不重复的元素的数量，它是不精确的，比较适合用来做大规模数据的去重统计。

7. Geo  地理位置    存储坐标值。  也可以进行位置距离计算，或者根据半径计算位置等。

8. Bitmaps：可以对某个数据的bit进行操作，存储0和1两个状态。  可以用来实现**布隆过滤器**。

## 内存淘汰策略

**Redis**的过期策略，是有**定期删除+惰性删除**两种。

**定期删除：**默认100s就随机抽一些设置了过期时间的key，去检查是否过期，过期了就删了。

一般我们线上对于数据都会设置一定的过期时间，如果全部扫描，就基本等于查数据库不带where条件，很消耗redis的性能。

那么上面的方式，可能会导致有些key一直没被随机到，里面就会存在大量的无效key。

那么**惰性删除**就出现了，它会等你来查询某个key的时候，检测这个key是否过期，如果过期就删除，不给你返回，没过期就正常返回。

那么**定期删除**和**惰性删除**都没涉及到的一些已经过期的key怎么办？这就要用到**内存淘汰机制**了。官网给到的内存淘汰机制是以下几个：

- no-eviction：当内存不足以容纳新写入数据时，新写入操作会报错，无法写入新数据，一般不采用。

- allkeys-lru：当内存不足以容纳新写入数据时，移除最近最少使用的key，这个是最常用的

- allkeys-random：当内存不足以容纳新写入的数据时，随机移除key

- allkeys-lfu：当内存不足以容纳新写入数据时，移除最不经常（最少）使用的key

- volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的key中，移除最近最少使用的key。

- volatile-random：内存不足以容纳新写入数据时，在设置了过期时间的key中，随机移除某个key 。

- volatile-lfu：当内存不足以容纳新写入数据时，在设置了过期时间的key中，移除最不经常（最少）使用的key

- volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的key中，优先移除过期时间最早（剩余存活时间最短）的key。

## 持久化方案

因为内存断电即失，所以持久化很重要。 

 RDB做镜像全量持久化（一整个表的全量数据），AOF做增量持久化（每次操作的日志）。

RDB会耗费很长的时间，不够实时，在停机的时候，可能会导致大量丢失数据，所以需要AOF来配合使用。

在redis实例重启时，会使用RDB持久化文件重新构建内存，再使用AOF重放近期的操作指令来实现重启之前的状态。

**Redis本身的机制**是 AOF持久化开启且存在AOF文件时，优先加载AOF文件；AOF关闭或者AOF文件不存在时，加载RDB文件；

加载AOF/RDB文件后，Redis启动成功； AOF/RDB文件存在错误时，Redis启动失败并打印错误信息

- RDB：**RDB** 持久化机制，是对 **Redis** 中的数据执行**周期性**的持久化。
- AOF：**AOF** 机制对每条写入命令作为日志，以 **append-only** 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快。

两种方式都可以把**Redis**内存中的数据持久化到磁盘上，然后再将这些数据备份到别的地方去，**RDB**更适合做**冷备**，**AOF**更适合做**热备**。

### 两种机制优缺点

#### RDB

优点：

会生成多个数据文件，每个数据文件分别都代表了某一时刻Redis里面的数据，比较适合做**冷备**。

比如可以定时同步数据。

RDB对Redis的性能影响非常小，因为在同步数据的时候他只是fork了一个子进程去做持久化的，而且数据恢复也比AOF来得快。

缺点：

- RDB都是快照文件，是默认五分钟甚至更久才会生成一次。`AOF`则最多丢一秒的数据，**数据完整性**上高下立判。
- RDB在生成数据快照的时候，如果文件很大，客户端可能会暂停几毫秒，甚至几秒。

#### AOF

优点：

- 一秒一次通过一个后台的线程`fsync`操作，最多丢失这一秒的数据。AOF对日志文件进行操作的时候是以追加的方式写数据，自然就少了很多磁盘寻址的开销，写入性能很好。

缺点：

- 一样的数据，AOF要比RDB文件大
- 会让redis的性能下降，但即便这样性能还是很高。

#### 如何选择？

单独用**RDB**会丢失很多数据，单独用**AOF**，你数据恢复没**RDB**来的快，真出问题的时候第一时间用**RDB**恢复，然后**AOF**做数据补全。

冷备热备一起上，才是互联网时代一个高健壮性系统的王道。

## 布隆过滤器

它实际上是一个很长的二进制向量和一系列随机映射函数，用于检索一个元素是否在一个集合中，优点是空间效率和查询效率都远远超过一般的算法，缺点是有一定的误识别率和删除困难。

### 原理

布隆过滤器的原理是，当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组（bit map）中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。

Bloom Filter跟单哈希函数Bit-Map不同之处在于：Bloom Filter使用了k个哈希函数，每个字符串跟k个bit对应。从而降低了冲突的概率。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/10/28/16e112fbd031fe71~tplv-t2oaga2asx-watermark.awebp)

### 过程

先把我们数据库的数据都加载到我们的过滤器中，比如数据库的id现在有：1、2、3

那就用id：1 为例子他在上图中经过三次hash之后，把三次原本值0的地方改为1

下次数据进来查询的时候如果id的值是1，那么我就把1拿去三次hash 发现三次hash的值，跟上面的三个位置完全一样，那就能证明过滤器中有1的

反之如果不一样就说明不存在了

### 应用场景

主要是用来防止缓存击穿（用户查询某个数据，缓存中没有，就要去mysql中查询，总是查询这样的数据，就出现了缓存穿透）

简单来说就是你数据库的id都是1开始然后自增的，那我知道你接口是通过id查询的，我就拿负数去查询，这个时候，会发现缓存里面没这个数据，我又去数据库查也没有，一个请求这样，100个，1000个，10000个呢？你的DB基本上就扛不住了，如果在缓存里面加上这个，是不是就不存在了，你判断没这个数据就不去查了，直接return一个数据为空不就好了嘛。.

**缺点：**

1. 牺牲了判断的准确率和删除的便利性
   1. 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。如果bloom filter中存储的是黑名单，那么可以通过建立一个白名单来存储可能会误判的元素。
   2. 删除困难，一个元素会映射到bit数组上k个位置为1，删除的时候，不能简单的把它们变成0，这会影响其它元素的判断。

## 缓存击穿

比如说微博出现热点，所有人都访问某一个值，当这个key值失效的一瞬间，所有的请求会去访问数据库，可能会导致宕机。

解决方案：

1. 设置热点数据永不过期

## 缓存雪崩

是指在某一个时间段，缓存集中过期失效，Redis宕机。

解决：

**给数据的过期时间加上一个随机值，让缓存失效的时间尽量均匀。**

# 数据结构

## 数组

## 链表

## 二叉树

## 排序

冒泡排序：每次都把一个最大的放到最后。

```go
func bubbleSort(arr []int) {
	for i := 0; i < len(arr)-1; i++ {
		for j := 0; j < len(arr)-1-i; j++ {
			if arr[j] > arr[j+1] {
				// 如果左边的数大于右边的数，则交换，保证右边的数字最大
				swap(arr, j, j+1)
			}
		}
	}
}

// 交换元素
func swap(arr []int, i int, j int) {
	temp := arr[i]
	arr[i] = arr[j]
	arr[j] = temp
}
```



选择排序：每次都选择一个最小的放到前面。

```go
func selectionSort(arr []int) {
	var minIndex int
	for i := 0; i < len(arr)-1; i++ {
		minIndex = i
		for j := i + 1; j < len(arr); j++ {
			if arr[minIndex] > arr[j] {
				// 记录最小值的下标
				minIndex = j
			}
		}
		// 将最小元素交换至首位
		temp := arr[i]
		arr[i] = arr[minIndex]
		arr[minIndex] = temp
	}
}
```

插入排序：

- 交换法：在新数字插入过程中，不断与前面的数字交换，直到找到自己合适的位置。
- 移动法：在新数字插入过程中，与前面的数字不断比较，前面的数字不断向后挪出位置，当新数字找到自己的位置后，插入一次即可。

从第二个数开始，插入到对应的位置。

![img](https://www.yuque.com/api/filetransfer/images?url=https%3A%2F%2Fimgconvert.csdnimg.cn%2FaHR0cHM6Ly9iZG4uMTM1ZWRpdG9yLmNvbS9maWxlcy91c2Vycy82MDMvNjAzMTUyNy8yMDIwMDgvTnN4YWdJSG1fdXhMVC5naWY&sign=7d0d87674a3c60936a833312caec6ade6dc97f1febed26ff640befcc15080346)

快排：

选择一个基数，比基数大的放右边，比基数小的放左边。

然后再选择左右两个数组的基数。

# 计算机网络基础

## TCP/IP四层模型

下面是OSI七层模型：

![image-20220214145512547](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214145512547.png)

平时中，使用的是更常见的TCP/IP四层模型。

![image-20220214150015042](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214150015042.png)

**网络接口层**：主要的数据结构是数据帧，数据帧由三个部分组成——帧首部、帧数据、帧尾部。

**网络层**：主要的数据结构是数据报，数据包由两部分组成——`网络层协议首部`和`网络层协议数据`两部分组成。

**传输层**：传输层的数据分为`协议首部`和`协议数据`，这两部分又是网络层的`协议数据`。

**应用层**：上一层的协议数据是本层的`协议头`和`数据`组成的。

可以看到，从上到下，会有一个清晰的分层结构。

![image-20220214150236704](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214150236704.png)

##### 网络层

网络层提供主机之间的通信，它的目的是向上提供`无连接的`，尽最大努力交付的`数据报服务`。网络层不提供服务质量的承诺。

它有这么几个特点：

1. 不需要建立连接
2. 每个数据报单独路由
3. 每个数据报有完整的目标地址
4. 不提供可靠的连接
5. 达到终点可能无序：每个数据报都是单独的确定路径，那么到达终点时就可能没有顺序。 
6. 由终点进行差错控制 

##### 传输层

传输层提供主机间不同进程的通信，为上一层的应用层提供通信服务，并且屏蔽了下面的核心网络细节。

当传输层采用TCP协议时，这条通信信道就是一条可靠的通信信道，而尽管下面的网络是不可靠的。

##### 应用层

关键协议：HTTP协议、FTP协议、SMTP协议、DNS

主要定义了运行在不同端系统上的应用程序进程如何互相传递报文。

也就是**提供不同应用之间的通信**。

应用层还定义了进程交换的报文类型、报文的语法、字段的含义、进程如何发送数据，怎么发送数据等。



## HTTP版本0.9/1.0/1.1/2.0的演化

在1991年发布了HTTP 0.9。主要解决的网页的排版和文字的结构问题

1996年发布了HTTP 1.0，主要是添加了一些图片，文件的颜色和超链接等等的内容 

![image-20220214154106404](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214154106404.png)

随着HTTP版本变化的时代演进：

![image-20220214154322329](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214154322329.png)

通过时代的变化，我们也能看出HTTP不同版本的变化：

**HTTP 0.9**：因为设计的缺陷，只能和老的一些客户端交互；只支持GET方法，也就是只能取网页的信息；不能修改网页的内容；不支持视频、图片，颜色也不丰富；主要是各种HTML对象。

**HTTP 1.0**：在0.9的基础上进行改良，现在很多的项目都是基于1.0/1.1来对外进行服务的；这个版本增加了其它的方法，比如POST方法，PUT方法，DELETE方法等等；增加了图片内容；

**HTTP 1.1**：支持长连接，1.1主要是从性能、效率提高，节省带宽的角度去考虑的。

**HTTP 2.0**：这些新技术都是为了更加极致的提高性能所设计的。

![image-20220214154311356](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214154311356.png)

### 长连接：keep-alive

HTTP是应用层的协议，它下面是`传输层`，具体可以由`TCP`来提供服务，那么在通过HTTP协议进行通信之前，需要让客户端和服务端进行TCP连接。

而TCP连接的建立需要经过三次握手，而断开连接的时候还需要进行四次挥手，所以频繁的建立和释放TCP连接需要很大的时间成本。

而`keep-alive`就是为了解决这个问题而诞生的一个功能。

可以看到，下面图的上半部分是短链接处理事务，一次连接只做一件事。

下半部分通过长连接，只建立了一个连接，在这个连接上不断的进行请求和响应，缩短了通讯时间，使用户打开网页的时候可以更快的去响应。

![image-20220214155551460](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214155551460.png)

### HTTP 2.0的特性

通过下面这张图我们可以简单的看到2.0版本有多厉害，同时渲染一张图，1.1需要14.7s的时间，而2.0只需要1.61s。 说明它在性能上是提升非常多的。

![image-20220214155816954](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214155816954.png)

而在2.0中，下面几个概念是面试官比较容易考的概念：

**一、多路复用**：通常表示在一个信道上传输多路信号或数据流的过程和技术。通过使用多路复用，通信运营商可以避免维护多条线路，节约运营成本。

如果把单路比作人与人之间写信，我给你写一封，你给我回一封——这种一寄一回的话。

那么多路复用就是人与人之间打电话，我可以说一句，对方回一句，也可以不断的去说话，双方的交流不会受到对方的影响，这样可以简单的认为是在一条链路上进行多个信号传输的例子。

**多路复用的特点**：

- 二进制分帧是基础，通信单位为帧
- 多请求并行不依赖多TCP连接
- 并行在一个TCP连接交互多种类型信息

如下图所示，1.1版本是一次请求，一次响应。

而2.0可以进行多次请求，多次响应。不过它的底层会进行区分这是第一次请求，还是第二次请求，以及在收到这些数据之后，如何组成一个完整的数据，这些在底层都有比较复杂的实现。

![image-20220214160648271](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214160648271.png)

**二、头部压缩**：

HTTP的头部是明文数据，在传输的时候是很占用带宽的。在2.0就提出了头部压缩的技术。

它有两个特性：

1. 面对固定的字段，比如get、post、put等关键字，它会在客户端和服务端都存储一个静态的字典表，这样就可以只把对应的`key`发送过来，然后再通过key来找到对应的`value`。
2. 面对用户输入的数据——不固定的值，通过Huffman编码之后发送，对方收到之后再进行解码。 Huffman编码是英文的压缩算法。

![image-20220214161012672](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214161012672.png)

**三、服务端推送**：

传统的页面渲染都是客户端进行请求，服务器进行响应。都是客户端主动的进行数据的获取。

在HTTP2.0版本中，提供了服务端推送的功能，就是服务端可以预测客户端需要哪些数据，不等客户端请求，主动的推送资源。

比如说下面这张图片，当客户端请求第一个资源的时候，想要渲染它，也要用到另外两个文件，那么服务端就不会再等客户端请求这两个文件资源，而是主动的推送给客户端。

![image-20220214175105576](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214175105576.png)

## HTTP/HTTPS协议

### 报文结构

左边是请求报文的组成部分，右边是应答报文的组成部分。

![image-20220214175636551](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214175636551.png)

请求报文中几个比较关键的部分：**请求方法**、**请求地址**、**请求头/应答头**

应答报文中几个比较关键的部分：**状态码**、**HTTP版本**、**状态解释**



**请求报文的具体例子**：

![image-20220214175912034](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214175912034.png)

当我们访问慕课网的时候，会返回这样的报文数据信息：

![image-20220214180021850](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214180021850.png)

### 请求方法

HTTP请求的本质是对服务器资源进行操作的过程（增删改查+系统功能），通过定义不同的方法以清晰的实现不同操作是必要的。



**GET**：最常用的方法，常用于请求服务器的某个资源。

**HEAD**：和GET类似，但服务器在响应中只返回首部。 比如说可以只查看状态码是否正常。

**POST**：向服务器写入数据，进行新增操作。

**TRACE**：观察请求报文到达服务器的最终样子， 主要是现在的web服务架构越来越复杂，一个请求可能经过防火墙，经过代理，或者经过一定转化，最终才到达最终的服务器，经过这些服务之后，可能会改变原始的请求，这个方法可以看到到服务端最终的样子。

**PUT**：写入资源，进行修改操作。

**DELETE**：请求服务器删除所指定的资源。

**OPTIONS**：服务器返回它所支持的各种操作资源的方法。

![image-20220214182544045](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214182544045.png)

#### 幂等操作

**幂等操作**：幂等操作只其任意多次执行所产生的影响均与一次执行的影响相同。

**幂等函数**：幂等函数是指可以使用相同参数重复执行，并能获得相同结果的函数。 

比如说后台有一个接口，可以实现加1的功能，每请求一次，变量的值就加1，每请求一次的值都和上一次不同，每请求一次，它都会发生一些影响，所以它并不是一个幂等的操作。

而如果后台有一个接口，当调用这个接口的时候，传送一个参数5，可以把变量设为5，不管这个接口请求多少次，这个值都只会是5，这个操作就是一个幂等操作了。



我们前面看到的各种请求方法中：

幂等操作：`GET`、`HEAD`、`TRACE`、`OPTIONS`

其它：`PUT`不一定是幂等操作，需要看具体后台的实现。`POST`也不确定，取决于后台的实现。`DELETE`也不确定，取决于后台的实现。

![image-20220214183205605](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214183205605.png)

### 状态码

![image-20220214183534179](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214183534179.png)

几个比较常用的状态码如下：

`200`：OK。  表示请求没有问题，实体的主体部分包含了所请求的资源。

`204`：No Content。  请求成功了，但是应答没有任何内容。响应报文中只包含若干首部和一个状态行，没有实体的主体部分。

`304`：Not Modified。  所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。 也就是客户端所请求的资源是没有被修改的，客户端可以继续使用本地的资源。

`400`：Bad Request。 构建报文的时候，客户端请求语法错误，服务器无法理解。

`401`：Unauthorized。 请求客户端在获取对资源的访问权之前，对自己进行认证。即请求资源之前没有鉴权。

`403`：Forbidden。  当前的这个客户端没有权限去请求这个资源。

`404`：Not Found。 用于说明服务器无法找到所请求的URL。 比如说访问一张图片，但是没有这张图片，就会返回404错误。

`500`：Internal Server Error。 服务器内部错误，无法完成请求。

`502`：Bad Gateway。  网关或者代理出现了问题。  作为网关或者代理工作的服务区尝试执行请求时，从远程服务器接收到了一个无效的效应。

`503`：Service Unavailable。 服务器现在无法为该请求提供服务。 常见于服务宕机，服务无法正常运行的时候。

`504`：Gateway Timeout。  网关或者代理无法在一定时间内从服务器中获取响应。

通常，我们的通信模型，都是如下：

![image-20220214193057631](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214193057631.png)

### 安全传输模型

用户A和用户B在进行通信，但是网络传输是很不安全的，可能会被用户C进行截获，或者用户C进行伪装虚假的信息发送给用户B。

因此，用户A可以对数据进行加密，这样用户C即便获得信息，在理想情况下也无法解密。 然后到达用户B那里，再通过密钥进行解密。

其中，**密钥**是指明文和密文互相转换的算法中输入的参数，分为**对称密钥**和**非对称密钥**。

![image-20220214193838957](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214193838957.png)

#### 古典密码学

可以看到下面有两种方式，左边是置换密码表，可以在左边一列中任选一行，比如选择c行，那么字母C就代表字母A，字母D就代表字母B，依次这样替换。

右边代换密码表的意思是随意的让26个英文字母之间进行映射，然后得出一个代换密码表。

![image-20220214194424349](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214194424349.png)

但是这种密码加密的方式很容易破译。

比如说有论文进行分析过，在英文文章中各字母出现的频率，那么就可以把密文中字母出现的频率进行对应，就能得到明文了。

![image-20220214194812431](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214194812431.png)

#### 对称加密和非对称加密

在对称加密中，密钥a和密钥b是同一份密钥，这种通过一份密钥来进行加密和解密的方式就是对称加密。

![image-20220214194952981](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214194952981.png)

非对称加密就是加密和解密用的是不同的密钥。 加密用的叫公钥，给大家使用，对外公开。解密用的叫私钥，自己使用，不对外公开。

RSA是最具影响力，也是最常见的算法。

![image-20220214195050119](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214195050119.png)

**两者的对比**：

因为非对称加密的公钥和私钥是分开保存的，所以安全性会更高，又加上他用了一些更复杂的算法，所以它的运算效率会更低一点。

![image-20220214195323839](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214195323839.png)

### 散列算法

哈希函数可以把原来的信息压缩成一个等长字符串，而且从这个字符串看不出原来信息的样子。

如果两个内容通过哈希函数得到了不一样的结果，那么说明这两个内容肯定是不一样的。

但是如果有两个一样的哈希值，并不能说他们原来的内容一定是一样的，因为哈希函数有**哈希碰撞**的概念。

![image-20220214195543953](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214195543953.png)

散列算法常用在项目中使用，比如我们写web项目时，经常会把用户的密码通过`md5`加密的方式存储在数据库中，这样即便密码出现了泄漏，也无法快速的得到密码。

但是它仍然有对应的安全问题，比如黑客通过某种方式拿到密码之后，它可以拿到这个密文去和自己庞大的哈希结果字典表进行一一匹配。

因为`123456`这串字符串所对应的md5加密值是不会改变的，这样我本身只要有庞大的映射关系，就能破译对应的密文。

![image-20220214200104807](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214200104807.png)

所以为了避免这个事情，在通过md5加密时，还会进行一个加盐操作，也就是在进行加密的时候，通过在用户原字符串后加上一些`自定义字符串`，来获取对应的哈希值。

这样即便黑客获取到了这串md5值，因为不知道后面的自定义字符是什么，所以也无法进行匹配，这样就进一步加大了黑客破解的难度。

![image-20220214200339277](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214200339277.png)

另外，哈希散列算法严格意义上不能算加密算法，因为无法解密。 

![image-20220214200451943](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214200451943.png)

### HTTP和HTTPS协议的区别

![image-20220214200729152](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214200729152.png)

### TLS

它是在传输层和应用层之间的一层协议，对数据进行加密后传输。

它其中结合了对称加密、非对称加密技术设计的安全协议。

![image-20220214200819656](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214200819656.png)

#### 数字证书

数字证书是可信任组织颁发给特定对象（一些大机构）的认证。

右边是证书的一些基本内容，从`公钥`我们可知证书设计的时候用的是非对称加密。

![image-20220214201014144](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214201014144.png)

下面可以看到HTTPS建立连接的过程：

1. 对443端口进行TCP连接。
2. 进行SSL安全参数握手，握手之后双方能得到一个对称的密钥，这个密钥是通过非对称加密的过程所得到的。
3. 双方拿到这个对称密钥之后，就可以对数据进行加密和解密了。

![image-20220214201309971](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214201309971.png)

##### SSL安全参数握手具体过程

1. 客户端给服务器发送随机数1和加密算法（对称加密算法）
2. 服务器返回随机数2，以及服务器自己的数字证书。  （通过这一步确定了对称加密算法）
3. 客户端向`可信任机构`确定证书的有效性，然后通过证书的公钥来加密随机数3，发送给服务器，服务器通过自己证书的私钥来解密随机数3。 这样即便随机数3的密钥意外泄露了，对方也没有私钥来解密。
4. 双方根据最开始确定的对称密钥对随机数1/2/3进行生成对称密钥。 双方使用对称密钥进行加密通信。

![image-20220214201605093](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214201605093.png)

因为数字1/2/3的加密过程没有经过传输，所以没有泄露风险。

![image-20220214201620440](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214201620440.png)

那为什么不直接使用非对称加密来通信？

1. 双方都要存储一份对方的公钥，这个成本比较高。
2. 非对称加密和解密运算量要大很多。

为了避免这两个问题，就设计了上面比较复杂的步骤，最后通过对称加密来进行最终的加密通信。



## DNS工作流程

### DNS是什么？

我们去访问淘宝所使用的`www.taoobao.com`这样的字符串被称为域名，它是帮助我们记忆的。

但是实际上进行通信的还是`Ip + 端口`，比如`115.182.41.180:443`。

所以当我们去访问域名的时候，它会去查询DNS域名服务器，然后获取到对应的IP地址进行转向访问。

![image-20220214203539016](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214203539016.png)

### DNS工作原理

首先，我们要更详细的认识一下域名的组成，如下图所示：

顶级域名分为国家和通用两种，国家的就是各个国家所使用的顶级域名。

通用域名比如`com`代表一个公司的顶级域名，`net`一般表现为互联网公司。`gov`一般表示政府才会采用的域名。

![image-20220214204031140](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214204031140.png)

#### 域名分层

域名可以看到有下面这样的分级概念。

![image-20220214204359183](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214204359183.png)

#### 域名服务器分层

首先根域名服务器会存储顶级域名服务器的地址，然后顶级域名服务器也会存储权威域名服务器。

比如是顶级域名是cn的，就会访问cn域名服务器，顶级域名是com的，就会访问com域名服务器。

这样可以分散域名服务器的压力。

![image-20220214204459599](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214204459599.png)

#### DNS工作原理

DNS工作原理有两种，一种是迭代查询，一种是递归查询。



**迭代查询**：

比如说客户端要访问`www.baidu.com`这个域名。

它首先会在本地查询一下有没有这个域名所映射IP的缓存，如果没有的话先请求本地服务器，本地服务器会去请求根域名服务器，根域名服务器会返回`com域名服务器`的地址，然后找到顶级域名服务器返回`baidu.com`所对应的权威域名服务器地址，然后再访问权威域名服务器找到`www.baidu.com`这个地址的IP地址，最终返回给客户端。

![image-20220214204929763](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214204929763.png)

**递归查询**：

直接从头找到尾，然后再逐层的返回。

![image-20220214205347538](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220214205347538.png)



# 操作系统

## 线程、进程、协程

#### 什么是进程？

1. 进程是**系统进行资源分配和调度的基本单位**。这意味着进程和进程的资源之间是相互隔离的。
2. 进程作为程序**独立运行的载体保障程序正常执行**。可以把进程看做是为了管理程序而设计的一个概念。
3. 进程的存在**使得操作系统资源的利用率大幅提升**。

### 什么是线程？

- 在20世纪60年代提出进程的概念，它是操作系统进行运行调度的最小单位，一般称为`Threads`。

- 它包含在进程之中，一个进程可以创建很多的线程，它更轻量级，也是进程中世纪运行工作的单位。
- 一个进程可以并发多个线程，每个线程执行不同的任务。**提高系统内程序并发执行的程度**。

对于进程的管理有进程控制块（PCB），同样的，对于线程也有线程控制块（TCB）。

假如我们的CPU有两个核，如下图，一个进程只能调动其中一个CPU工作，这工作效率就是50%。

如果一个进程开辟了两个线程，就可以在两个核中并发运行，工作效率就是100%。

![image-20220215202332904](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220215202332904.png)

#### 提出线程和提出进程的区别

1. 提出进程是让操作系统更好的管理程序，使得多道程序可以更好的去管理。提出线程是降低程序内并发执行所付出的开销，以及提高程序内并发执行的程度。
2. 进程的提出是方便操作系统的管理，线程的提出是为了提升程序的并发量，吞吐量。

### 进程和线程的关系

 操作系统在分配资源的时候是以进程为单位的，它不会给线程分配资源，**进程的线程共享进程资源**，线程本身是不拥有资源的。

![image-20220215201819911](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220215201819911.png)

**线程的并发性**：

**进程间并发**：比如CPU有两个核，同时运行两个线程，这两个线程是在不同的进程中，这两个线程之间的交互就是进程间并发。

**进程内多线程并发**：比如CPU有两个核，同时运行两个线程，这两个线程在同一个进程中，这就是进程内多线程并发。

![image-20220215201941252](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220215201941252.png)

#### 协程是什么？

协程又被称为`微线程`、`纤程`、`协作式线程`。协程可以看做是`协作式线程`的缩略称呼。

协程为什么会被叫做`协作式线程`呢？

我们把下图的一根线当做用户态和内核态的分界线，上面的是用户态，下面的是内核态。

我们平常说的`线程`，就是在内核态中的线程，线程和协程之间的关系是用户态中的多个协程可以对应一个线程。

协程只会在用户态中运行，由用户自己调度，内核态是无法感知，也无法干涉的。

![image-20220215220624642](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220215220624642.png)

那么把它叫做`协作式线程`的原因是因为它有`协作运行`和`让步（yield）`的特点。

比如一段程序逻辑，按照单线程的方式去执行，就是一块一块的去执行。

而如果有协程的加入，就可以实现某一段代码让协程1执行，某一段代码让协程2执行，他们是主动的让步给对方去做，而不是抢夺式的。

那么最终在内核中的执行顺序也是这样的表示。

![image-20220215221112093](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220215221112093.png)



#### 协程的特点

1. 比线程有更小的粒度
2. 运行效率更高
3. 可以支持更高的并发

可以类似的理解为一个线程内有很多的协程，但其实协程的本质是`用户级线程`。而我们平常所说的`线程`指的是内核级线程，内核级线程是由操作系统所提供的。

而协程，或者`用户级线程`，是由用户态的程序所提供的。 

![image-20220215220119365](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220215220119365.png)

### 协程的优缺点

- 调度、切换、管理更加轻量，协程设计的原因是可以减少上下文切换的成本。
- 内核无法感知协程的存在，所以如果协程调度本身出问题的话，内核也无法去干预。 
- 内核无法感知多协程的存在，CPU只能感知到线程，所以只能对线程进行调度，因此协程无法发挥CPU多核的优势。
- 协程主要运用在多IO的场景，比如高并发的用户接入，因为协程切换成本更低，所以多协程比多线程能够支持更高的接入。 这个接入主要是指网络IO。

## 进程调度算法

先来先服务 FCFS    按照进程到达的先后次序执行

短作业优先  SJF    按照进程执行时间的长短，越短的优先。

高响应比优先 HRRN     按优先权大的开始算，优先权=（等待时间+执行时间）/执行时间

## 进程状态模型

### 进程的五个状态

进程的状态可以划分为五个状态：

1. **创建态**：先分配PCB（进程控制块）的信息，然后再把这些数据插入到就绪队列中。创建进程时拥有PCB，但是其它资源还没有就绪的状态称为创建状态。 （进程的创建不仅仅可以通过操作系统，操作系统提供fork函数接口来供我们通过某种方式创建进程 ）
2. **就绪态：**当其它的资源都准备好，只差CPU资源的使用权的状态称为就绪状态。
3. **运行态**： 进程获得CPU之后，其程序正在执行就称为运行态。在单处理机（单核）中，在某个时刻只能有一个进程是处于执行状态。
4. **阻塞态**：进程因某种原因：其它设备未就绪（网卡，磁盘等等），无法继续执行。 然后进程会主动放弃CPU的状态，这种状态就是阻塞态。
5. **终止态**：进程结束，由系统清理或者归还PCB的状态称为终止状态。



通过下图我们可以看到五种状态之间的关系。

进程创建完成之后，如果各项资源准备就绪，就会进入就绪态，当进程处于就绪的状态时，可以通过CPU的调度进行执行，如果CPU调度的时间片用完了，但是任务还没有执行完成，就继续回到就绪态，等待CPU的进程调度。

否则任务执行完成进入终止态。

如果在执行中去请求某些资源，但是这个资源因为某种原因不能马上获取到，会切换到阻塞态，当这个动作完成之后，还会继续回到就绪态。

等待CPU的进程调度执行下面的任务。

![image-20220215195600538](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220215195600538.png)

### 阻塞、非阻塞、同步、异步

#### 阻塞、非阻塞

**阻塞状态**：比如在io读写（或者读写网络）的时候，由于磁盘没有那么快，需要一定的时间，那么在这段时间进程的状态就被称为阻塞态。进程会在阻塞的时候停止运行，这就是**同步**。

**非阻塞状态**：比如在io读写的时候，由于磁盘没有那么快，需要一定的时间，但是这个时候进程不会一直在这里等待，会去做别的事情，等到这个读写工作完成之后，等到设备来告诉进程，这个任务已经ready了，这个时候进程才会去完成这个任务，去读取这个数据。 进程从始到终一直都在运行，它不会一直等待这个事情的进行，而是会并行的去执行别的事情，等原来的事情结束之后再回来继续做剩下的事情，这就是**异步**。

![image-20220215200006275](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220215200006275.png)

我们可以看到，同步和异步强调的是**消息通信机制**。同步会一直等待程序的处理，然后最后返回。异步会在程序进行处理的时候去做其它的事情，等这个程序通知进程的时候，再回去进行执行。

而阻塞和非阻塞强调的是**程序在等待调用结果时的状态**。

## 虚拟内存

### 虚拟内存为什么出现？解决什么问题？ 

因为有些进程实际需要的内存很大，会超过物理内存的容量，又因为多道程序设计，会更一步稀释物理内存的空间，而我们也不可能无限的增加物理内存，总有不够的时候。

虚拟内存是操作系统内存管理的关键技术，能够使多道程序运行和大程序运行成为现实，它会把程序使用内存进行划分，将部分暂时不使用的内存放置在辅存中。

逻辑地址空间就是我们在运行一个程序的时候，变量的存储地址，这是一个程序内交互的过程，而逻辑地址最终需要映射在物理地址空间中，才能真正的去操作数据。![image-20220216081452273](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220216081452273.png)

那么也就是说，程序运行的时候，不需要把全部的内容都装入内存，如果访问页不再内存，则发出**缺页中断**，发起**页面置换**。

从用户层面来看，程序拥有很大的空间，即虚拟内存，是对物理内存的补充，速度接近于内存，成本接近于辅存。

页面置换算法：

![image-20220219134300388](https://gitee.com/whyunfei/blogimage/raw/master/img/image-20220219134300388.png)



# Docker、Linux、Nginx

## 基本命令

### Docker

```dockerfile
# 镜像相关
docker images # 查看所有镜像
docker rmi 镜像id # 删除镜像
docker build -f dockerfile -t 镜像名字:版本 . # 构建镜像
# ------------------------------------------
# 容器相关
docker rm - f 容器id   # 删除容器
docker ps # 查看当前正在运行的容器
docker ps -a # 查看所有容器
docker start 容器id/容器名字 # 启动容器
docker stop 容器id/容器名字 # 停止容器
docker restart 容器id/容器名字 # 重启容器
docker run -itd --name ubuntu_test ubuntu /bin/bash # 通过镜像生成容器
docker run -it -v /wangyaqing/project:/project/ --name centos_test02 centos_go:1 /bin/bash # 可以通过-v命令来挂载文件映射

docker attach 容器 # 进入容器
docker exec -it smart_campus /bin/bash # 也可以进入容器
```

# Git

## 基本命令

```shell
# 将当前代码保存到暂存区。 
git stash save "save message" 
git pull origin # 从远端拉取代码
git stash pop # 把最近存储的暂存区的代码弹出，并删除。  此时如果有冲突要解决冲突。
git add . # 把所有文件添加进去
# 代码的commit信息，需要按照下面的注释
# feat新功能，docs文档注释，fix修补bug，init项目初始化，opt优化和改善，比如弹窗提示信息，不改动具体功能和逻辑。style不影响代码运行的变动。refactor不是新增功能，也不是修改bug的代码变动。test新增测试。other用于难以分类的类别，一般是不使用，有时删除一些不必要的文件时可以使用。
git commit -m "fix:fix xx module."
git push origin HEAD:develop # 提交到远程的分支
# 一般来讲都是提交到自己的远程仓库中，然后再去项目仓库中把自己的代码和主仓库代码分支合并。

git reset HEAD # 如果后面什么都不跟的话 就是上一次add 里面的全部撤销了 
git reset HEAD # XXX/XXX/XXX.java 就是对某个文件进行撤销了
git reset --hard HEAD^ # 回退上一个版本
git reset --hard HEAD~n # 回退到n次提交之前
git log # 查看git历史版本号
git checkout 版本号 # 回退到某个版本号中，再通过git log查看，会发现这个版本号成第一个了。
```

# 项目

自己一共做过的项目：

1. 2020.8月-9月——线上迎新电子报道
2. 2021.2.15 - 2021.3.6 python flask 项目
3. 2021.8-9积分管理v2
4. 2021.10.20 - 2021.12.1 知乎爬虫项目

## 积分管理

### 遇到的问题

1. 数据库建表字段的讨论，根据原型图来归纳模块，以及每个人做的事情，再根据每个人事情去制定对应的待办，最终把这个待办能执行下去。  增长了我很多处理事情的经验。
2. 前端薄弱。 自己通过某种方式去学习

### 遇到的难点

这个项目服务于河南科技学院信工学院2000人的规模，而各个管理员在对积分进行同步和修改的时候，涉及到积分的并发修改问题。

解决方案：

## 微信公众号爬虫

这个项目当时是要爬取头条号，微博，百家号，微信公众号的文章数据，通过访问知乎的接口来获取某个平台的用户。

因为每个平台是分开的，我负责的是微信公众号爬虫，所以就只写了这一个模块。

它的难点主要是需要采集2000+公众号的历史文章（2021.9.15之后）和增量文章。 知乎方面提供用户的原始id和公众号名字。

而且要求增量文章10分钟，历史文章半个小时的时效性。

最开始想的是分解用户历史文章url的参数，首先通过fiddler抓包，找到历史文章的完整链接，然后在浏览器上打开，发现里面有好几个参数是算法随机生成的，而且具有时效性，找不到破解的方向，就放弃了。

就在githup，百度，google上搜索了现有的所有资料，最终发现微信公众号的爬虫有以下三种还可行的方案：

1. 微信公众平台中有一个搜索框暴露了一个api可以获取其它公众号的所有文章。   它的缺点是一个公众号一天只能调用这个api大概200次，如果被封了的话，需要等待24小时。
2. 逆向，逆向微信的问题在于难度很大，一时间无法攻克。
3. AnyProxy+Appium。 这种方式是通过运行安卓模拟器，然后通过程序来模拟人工操作，进行页面跳转，下滑来抓取对应的内容。   这种方式搭建起来比较麻烦，它的问题在于一个微信号只能翻100页左右，而且时效性远远达不到需求，一般2s一页。

经过很长时间的探索和尝试之后，采用了逆向 + 微信公众平台的策略：

首先通过python的pyautogui库可以识别图像，来对微信号进行自动关注。一个微信号一天稳定关注在100左右。我们找了10个微信号，挂在2台windows服务器上，通过三天的时间把所有公众号都关注了，然后不断的遍历用户列表，如果有新的公众号时，会自动关注。

通过逆向微信客户端可以实时获取到微信关注的公众号的推送文章，然后再解析这个文章的数据进行持久化。这样采取增量的时效性就是实时的。

接下来解决的问题就是存量的时效性，然后我们测试了很多微信公众平台这个接口，它有以下几个特征：

1. 一个号一天大概在150次接口访问，一页20篇文章，最终实验中每个号平均能产出1500篇文章左右，视用户本身的使用痕迹和活跃程度，这个数量会有上下浮动。
2. 频繁之后，通常需要24小时的时间恢复。
3. 一个公众号下可以有多个运营者，通过多个运营者的cookie可以干扰微信识别的难度。

最终设立了一套休眠机制，比如翻页时要休眠多长时间，访问多少次接口之后要休眠多长时间，最后通过一个列表维护16个微信公众号的cookie，分成两组，一个主，一个从，可以在出现问题的时候进行切换。

这16个微信公众号通过三天的时间，把所有公众号的存量跑完了，剩下的时候，一天公众号增加的不多，最多不超过10个用户，这些体量足够。

# 各个模块面经

一般面试前都要先自我介绍一下，一面都是问的基础性的问题，二面，三面一般都是部门总监，问的问题都是项目、架构、设计之类的。

## Go

### Go基础



**高频：**

1. GMP模型 
2. Golang Map底层（扩容机制）
3. defer函数的使用场景（延迟Close、recover panic） 
4. Golang GC(三色标记法，插入屏障、删除屏障、混合写屏障)
5. Channel的阻塞和非阻塞（顺带问了select用法）
6. 一致性哈希了解过吗？简单介绍下原理？一致性哈希的应用场景有哪些？为什么比普通哈希好？
7. 函数传指针和传值有什么区别？
8. new和make有什么区别？
9. 有缓存和无缓存channel的区别
9. 读取一个空channel会有什么问题？



**中频：**





**低频：**

1. 如何实现Map的有序查找（利用一个辅助slice） 
2. 2个协程交替打印字母和数字
3. 什么是内存逃逸，在什么情况下发生，原理是什么?
4. char *Ptr=0； *Ptr='a' 说明一下内存分配流程
5. Map可以用数组作为Key吗（数组可以，切片不可以）



### 第三方包

1. sync包了解吗 



### 进程、线程、协程和并发

**高频：**

1. 进程、线程、协程的介绍、区别、比较。
2. Golang协程间如何通信
3. channel底层源码
4. 



**中频：**



**低频：**

1. Mutex与RWMutex 

2. 怎么实现Map的并发安全(sync.Map，底层实际上用了一个Map缓存) 

3. 线程什么是私有的

4. 线程的局部变量被访问会造成什么

5. go 中用 for 遍历多次执行 goroutine会存在什么问题？怎么改进？

6. 如果要在每个goroutine中都获取返回值（捕获参数），有哪些方案？（全局参数、channel，闭包）

7. 分布式 ID 讲一下（九种方案 + 详细讲了号段、雪花[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)的原理）

8. goroutine的源码介绍

   

## 其它技术栈

### Es



**高频：**

1. ES搜索时各个节点怎么工作的？
2. 对ES的查询做了哪些优化？
3. 倒排索引的原理以及如何进行压缩的？
4. ES的搜索流程中，各个节点是怎么进行工作的？
5. ES中分词器有几部分？每一部分都是用来干啥的？



**中频：**



**低频：**



### 微服务

**高频：**

1. 讲一下微服务
2. 熔断和限流怎么做的？从源码的角度来说一下



**中频：**



**低频：**

1. gRPC为什么高效

1. `gRPC`用的什么协议？`TCP`三次握手？四次挥手？`FIN-WAIT-2`是什么时候的？

1. `RPC`有哪几种？这里还问了一个`流式 RPC`怎么巴拉巴拉什么处理之类的

1. RPC是基于TCP还是UDP？数据传输过程中的简单流程又是怎样的？

1. 客户端请求一个不存在的端口，会发生什么？

   



### 容器（docker、k8s，虚拟机）

1. docker的一些基本命令（删除、进入容器等等）
1. 简单介绍下docker和k8s，以及与虚拟机的区别



### linux

1. linux中top命令介绍下，可以查看哪些参数，你在用的时候关注哪些参数
2. epoll底层原理？[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)、双向[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)这样硬编
3. 



### nginx

1. 反向代理中客户端与服务端数据交换都是通过代理来传递的吗？还是由代理建立连接之后两者直接进行数据交换？



### 压力测试

1. 压测怎么压的？压测的QPS达到了多少？你在压测的过程中会关注哪些参数？

## 计算机基础



### 计算机网络

**高频：**

1. TCP三次握手、四次挥手，timewait，closewait状态

2. TCP和UDP的区别，TCP保证可靠的机制网络有多少层



**中频：**



**低频：**

1. tcp数据包的格式是什么？可选参数有哪些选项？
2. tcp拥塞控制介绍下？
3. HTTP1.0，1.1，2.0，3.0
4. 对称加密和非对称加密
5. HTTP的CA证书工作原理
6. 非对称加密慢怎么解决？
7. 了解socket编程吗，其中accept方法是什么
8. get、post方法有什么区别
9. DNS解析，比如迭代和递归查询
10. 四次挥手中，服务端请求断开连接的时候，客户端回复ACK确认后，就立即关闭连接，然后2MSL等待放在服务端为什么不可以？
11. 四次挥手时不需要close wait，等待服务端要发送数据时，一次性把ack和fin发过去可以吗？



### 操作系统

**高频：**

1. 虚拟内存、物理内存、共享内存介绍下？有什么区别和使用场景？

   

**中频：**



**低频：**

1. 进程和线程的区别是什么
2. 页的概念，linux中页的大小
3. 虚拟内存寻址
3. 什么是内核态和用户态？什么是系统调用？
3. 主机断电会发生什么？答断电操作系统就不能发送FIN了，如果是杀死进程操作系统会发送FIN的

### 计算机组成原理



### 数据结构



### 算法

1. [算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)：口撕[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)是否有环
2. 堆[排序](https://www.nowcoder.com/jump/super-jump/word?word=排序)、快速[排序](https://www.nowcoder.com/jump/super-jump/word?word=排序)的时间复杂度以及分别适用什么场景
3. [算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)：手撕快排
3. 手写[二分查找]() 
3. 爬梯子
3. 分苹果
3. 一个单向[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)，输出第一个节点指向最后一个节点，最后一个节点指向第二个节点，第二个节点指向倒数第二个节点这样以此类推
3. 最大频率栈(FreqStack)，比如入栈 5,7,5,7,4,5 第一次弹5，因为5频率最大，第二次弹7，因为5和7频率一样，但是7更靠近栈顶，依次弹出来是 5, 7, 5, 4, 7。
3. DFS和BFS，一般都有什么优化方案
3. 找文件里最大的100个数，建堆过程
3. 3个文件，找里面大家都有的数字（我讲的字典树）
3. 一个网站会有自己的QPS限制，当一分钟内的QPS超过阈值之后就拒绝请求，写代码模拟下这个过程
3. [二叉树](https://www.nowcoder.com/jump/super-jump/word?word=二叉树)的最近公共祖先，分别用递归法和非递归法来实现
3. [算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)：[找出[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)的入口节点]( https://leetcode-cn.com/problems/c32eOV/)

## mysql

**高频：**

1. 数据库索引，hash索引与B+树索引的适用场景，为什么用B+树索引
2. 主键与非主键和索引的关系（InnoDB主键一定是聚簇索引，非主键如果是索引的话，查询可能需要回表）
3. MYSQL事务的ACID
4. MySQL原子性怎么保证
5. redolog工作原理
6. MySQL四种隔离级别举例，幻读。乐观锁和悲观锁
7. mysql



**中频：**



**低频：**

1. 宕机恢复
2. undolog在宕机时怎么保证原子性



## redis

**高频：**

1. redis持久化有哪些？各自优势？谁更常用？
2. [redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)有哪些数据类型
3. 缓存雪崩，缓存穿透，缓存击穿，各自的解决办法
4. 

**中频：**



**低频：**

1. Redis为什么快（内存数据库，单线程IO多路复用）
1. redis使用单线程还是多线程？有多少个库？
1. hashmap原理
1. [redis](https://www.nowcoder.com/jump/super-jump/word?word=redis) 字典底层
1. Redis怎么去重，RDB和AOF



## 并发

### RabbitMQ或kafka

1. RabbitMQ的消息模型都有哪些？RabbitMQ都有哪些参数
2. 设计消息队列应该考虑些什么问题，消息持久化的文件存储格式应该怎么设计
2. Kafka消息积压问题



## 设计模式

1. 介绍除了单例与工厂模式外的设计模式（消费者模式）
1. 责任链

## 场景题

1. 实现一个接口C在指定时间内最大次数并发调用接口A与接口B 
2. 让你设计一个进程的数据结构，应该包括哪些数据字段以及分别对应的数据类型，为什么？
3. 如何并发100个任务，但是同一时间最多运行的10个任务（waitgroup + channel）
3. 有100G的文本文件，我要解析出这些文本中包含的URL并统计出来，取出其中的Top10，要求用并发编程加速。
3. 网页爬虫，每个网页会有很多超链接，都要递归爬完，爬过了就不爬了，怎么设计
3. 怎么在指定的路径里找所有文本文件中带有“abc”的内容
3. 几个相同的服务 A、B、C，挂了一个 A，REST API 怎么知道 A 挂了并调用 B？
3. 如果要你设计一个RPC框架，你主要会关注哪几个点，简单介绍下？



## 价值观问题

1. 怎么学习的？学习过程中遇到什么问题？怎么解决？具体是什么问题？ 
2. 有没有遇到过一些 BUG，然后解决完之后心情感到非常舒服的？具体是什么 BUG？ 
3. 你都是怎么写笔记的？（屏幕共享给面试官看我的笔记） 
4. 看过什么书？是随便翻翻还是看完了？（说了雨痕大佬的《Go语言学习笔记》和郑兆雄的《Go Web编程》，《Go语言学习笔记》在学校图书室我都借了三次看了三遍每次都有收益） 
5. 还有就是一些巴拉巴拉的问题，反正都是一些个人情况学习情况之类的？想不太起来了？
5. 未来职业规划和个人发展方向
5. 期望工作时间和薪资